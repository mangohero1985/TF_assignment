{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (5000, 28, 28) (5000,)\n",
      "Test set (5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_dataset = valid_dataset[:5000]\n",
    "  valid_labels = save['valid_labels']\n",
    "  valid_labels = valid_labels[:5000]\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_dataset = test_dataset[:5000]\n",
    "  test_labels = save['test_labels']\n",
    "  test_labels = test_labels[:5000]\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "* convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "* labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (5000, 28, 28, 1) (5000, 10)\n",
      "Test set (5000, 28, 28, 1) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 32\n",
    "num_hidden = 256\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  # four layer convolutional NN, {relu[(input -> conv)+bias]->Hidden}*2 --> linear*2\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "     tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 6.585915\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 50: 0.897148\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 100: 0.795110\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 150: 0.792732\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 200: 0.623030\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 250: 0.674460\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 300: 0.749752\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 350: 0.481340\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 400: 0.670745\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 450: 0.495346\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 500: 0.271155\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 550: 0.496540\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.1%\n",
      "Minibatch loss at step 600: 0.421300\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 650: 0.429811\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 700: 0.854494\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 750: 0.757108\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 800: 0.346939\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 850: 0.490422\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 900: 0.338417\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 950: 0.472043\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 1000: 0.334175\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 91.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "#\n",
    "with tf.Session(graph=graph,config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem1\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (nn.max_pool()) of stride 2 and kernel size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 128\n",
    "num_hidden = 512\n",
    "lamba = 5e-3\n",
    "SEED =66478\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  # four layer convolutional NN, {relu[(input -> conv)+bias]->Hidden}*2 --> linear*2\n",
    "  def model(data,train=False):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    pooling = tf.nn.max_pool(hidden,[1,2,2,1],[1,2,2,1],padding='VALID')\n",
    "    conv = tf.nn.conv2d(pooling, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    pooling = tf.nn.max_pool(hidden,[1,2,2,1],[1,2,2,1],padding='VALID')\n",
    "    shape = pooling.get_shape().as_list()\n",
    "    reshape = tf.reshape(pooling, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    if train:\n",
    "        reshape = tf.nn.dropout(reshape,0.5)\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden,0.5,seed=SEED)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    \n",
    "  \n",
    "  L2 = lamba*tf.nn.l2_loss(layer1_weights)+lamba*tf.nn.l2_loss(layer1_biases)+ lamba*tf.nn.l2_loss(layer2_weights)+lamba*tf.nn.l2_loss(layer2_biases)+ lamba*tf.nn.l2_loss(layer3_weights)+lamba*tf.nn.l2_loss(layer3_biases)+ lamba*tf.nn.l2_loss(layer4_weights)+lamba*tf.nn.l2_loss(layer4_biases)\n",
    "    \n",
    "  #### Rate decay\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.05, global_step,100000,0.95,staircase=True)\n",
    "    \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)+L2)\n",
    "  \n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost function\n",
    "tf.scalar_summary(\"loss\", loss)\n",
    "\n",
    "# Merge all summaries to a single operator\n",
    "merged_summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 89.395050\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 50: 73.888924\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 66.2%\n",
      "Minibatch loss at step 100: 71.957123\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 150: 70.199203\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 200: 68.323006\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 250: 66.677643\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 300: 65.073257\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 350: 63.114632\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 400: 61.935135\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 450: 60.190670\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 500: 58.494186\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 550: 57.463844\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 600: 55.826225\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 650: 54.441284\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 700: 53.499458\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 750: 52.013401\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 800: 50.483093\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 850: 49.325630\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 900: 47.909752\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 950: 46.965469\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 1000: 45.710651\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1050: 44.518951\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 1100: 43.423965\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1150: 42.466393\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 1200: 41.634823\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1250: 40.332375\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1300: 39.417847\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 1350: 38.449974\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1400: 37.730335\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 1450: 36.643372\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 1500: 35.936451\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 1550: 34.971973\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1600: 33.948109\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1650: 33.332916\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 1700: 32.337585\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 1750: 31.501465\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 1800: 30.917576\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 1850: 30.113798\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 1900: 29.368206\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 1950: 28.600197\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2000: 28.122543\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 2050: 27.062454\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2100: 26.530539\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 2150: 25.989988\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 2200: 25.225883\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2250: 24.560566\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2300: 24.181679\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 2350: 23.631075\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2400: 23.105238\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2450: 22.340305\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2500: 21.906618\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 2550: 21.262150\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2600: 20.683853\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2650: 20.350155\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2700: 19.685444\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 2750: 19.258286\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 2800: 18.846107\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2850: 18.390524\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 2900: 17.897543\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 2950: 17.483290\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 3000: 17.243412\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "valid_error = []\n",
    "train_error = []\n",
    "with tf.Session(graph=graph,config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as session:\n",
    "  \n",
    "# Set logs writer into folder /tmp/tensorflow_logs\n",
    "  summary_writer = tf.train.SummaryWriter('/home/wchen/tmp/con2d_logs', graph_def=session.graph_def)\n",
    "\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      train_accuracy = accuracy(predictions, batch_labels)\n",
    "      print('Minibatch accuracy: %.1f%%' % train_accuracy)\n",
    "      valid_accuracy =accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "      train_error.append(100-train_accuracy)\n",
    "      valid_error.append(100-valid_accuracy)\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7dff850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n86mfrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x87b6510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = len(valid_error)\n",
    "step = np.arange(size)\n",
    "plt.plot(step,train_error)\n",
    "plt.plot(step,valid_error)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard on port 6006\n",
      "(You can navigate to http://localhost:6006)\n",
      "WARNING:root:Found more than one graph event per run.Overwritting the graph with the newest event\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:12] \"GET / HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /lib/css/global.css HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/d3/d3.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/lodash/lodash.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/plottable/plottable.css HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/plottable/plottable.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/graphlib/dist/graphlib.core.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/dagre/dist/dagre.core.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/polymer/polymer.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/webcomponentsjs/webcomponents-lite.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-ajax/iron-ajax.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-collapse/iron-collapse.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-list/iron-list.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-button/paper-button.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-checkbox/paper-checkbox.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-dropdown-menu/paper-dropdown-menu.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-header-panel/paper-header-panel.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-icon-button/paper-icon-button.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-item/paper-item.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-progress/paper-progress.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-menu/paper-menu.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-radio-button/paper-radio-button.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-radio-group/paper-radio-group.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-slider/paper-slider.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-styles/paper-styles.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-toggle-button/paper-toggle-button.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-toolbar/paper-toolbar.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /dist/tf-tensorboard.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/polymer/polymer-mini.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/polymer/polymer-micro.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-resizable-behavior/iron-resizable-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-material/paper-material.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-ripple/paper-ripple.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-behaviors/paper-button-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-flex-layout/iron-flex-layout.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-range-behavior/iron-range-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-styles/color.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-icon/iron-icon.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-behaviors/paper-inky-focus-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-styles/default-theme.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-behaviors/paper-checked-element-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-a11y-keys-behavior/iron-a11y-keys-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-selector/iron-selectable.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-ajax/iron-request.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-flex-layout/classes/iron-flex-layout.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-styles/shadow.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-styles/typography.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-menu-button/paper-menu-button.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-behaviors/iron-control-state.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-behaviors/iron-button-state.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-icons/iron-icons.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-form-element-behavior/iron-form-element-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-validatable-behavior/iron-validatable-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-input/iron-input.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input-container.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input-error.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input-char-counter.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-header-panel/paper-header-panel.css HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-item/paper-item-shared-styles.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-menu-behavior/iron-menu-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-menu/paper-menu-shared.css HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-behaviors/paper-ripple-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-meta/iron-meta.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-checked-element-behavior/iron-checked-element-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-selector/iron-selection.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/promise-polyfill/promise-polyfill-lite.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-flex-layout/classes/iron-shadow-flex-layout.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/font-roboto/roboto.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-dropdown/iron-dropdown.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/neon-animation/animations/fade-in-animation.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/neon-animation/animations/fade-out-animation.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-menu-button/paper-menu-button-animations.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/iron-iconset-svg/iron-iconset-svg.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:13] \"GET /external/paper-input/paper-input-addon-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-selector/iron-multi-selectable.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/promise-polyfill/Promise.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-overlay-behavior/iron-overlay-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/neon-animation/neon-animation-runner-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/neon-animation/animations/opaque-animation.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-dropdown/iron-dropdown-scroll-manager.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/neon-animation/neon-animation-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/neon-animation/web-animations.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-fit-behavior/iron-fit-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-overlay-behavior/iron-overlay-backdrop.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/iron-overlay-behavior/iron-overlay-manager.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/neon-animation/neon-animatable-behavior.html HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /external/web-animations-js/web-animations-next-lite.min.js HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /runs HTTP/1.1\" 200 -\n",
      "WARNING:root:IOError [Errno 2] No such file or directory: '/usr/lib/python2.7/site-packages/tensorflow/tensorboard/favicon.ico' on path /usr/lib/python2.7/site-packages/tensorflow/tensorboard/favicon.ico\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:14] \"GET /favicon.ico HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:17] \"GET /runs HTTP/1.1\" 200 -\n",
      "WARNING:root:IOError [Errno 2] No such file or directory: '/usr/lib/python2.7/site-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg' on path /usr/lib/python2.7/site-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:18] \"GET /lib/svg/summary-icon.svg HTTP/1.1\" 200 -\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:34] \"GET /graph?run=con2d_logs HTTP/1.1\" 200 -\n",
      "WARNING:root:IOError [Errno 2] No such file or directory: '/usr/lib/python2.7/site-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg' on path /usr/lib/python2.7/site-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg\n",
      "172.16.28.44 - - [12/Feb/2016 13:55:44] \"GET /lib/svg/summary-icon.svg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir='/home/wchen/tmp/con2d_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
