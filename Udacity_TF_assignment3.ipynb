{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (5000, 28, 28) (5000,)\n",
      "Test set (5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_dataset = valid_dataset[:5000]\n",
    "  valid_labels = save['valid_labels']\n",
    "  valid_labels = valid_labels[:5000]\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_dataset = test_dataset[:5000]\n",
    "  test_labels = save['test_labels']\n",
    "  test_labels = test_labels[:5000]\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "* convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "* labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (5000, 28, 28, 1) (5000, 10)\n",
      "Test set (5000, 28, 28, 1) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 32\n",
    "num_hidden = 256\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  # four layer convolutional NN, {relu[(input -> conv)+bias]->Hidden}*2 --> linear*2\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "     tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 6.585915\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 50: 0.897148\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 100: 0.795110\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 150: 0.792732\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 200: 0.623030\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 250: 0.674460\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 300: 0.749752\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 350: 0.481340\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 400: 0.670745\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 450: 0.495346\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 500: 0.271155\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 550: 0.496540\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.1%\n",
      "Minibatch loss at step 600: 0.421300\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 650: 0.429811\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 700: 0.854494\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 750: 0.757108\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 800: 0.346939\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 850: 0.490422\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 900: 0.338417\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 950: 0.472043\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 1000: 0.334175\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 91.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "#\n",
    "with tf.Session(graph=graph,config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem1\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (nn.max_pool()) of stride 2 and kernel size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 128\n",
    "num_hidden = 512\n",
    "lamba = 5e-3\n",
    "SEED =66478\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  # four layer convolutional NN, {relu[(input -> conv)+bias]->Hidden}*2 --> linear*2\n",
    "  def model(data,train=False):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    pooling = tf.nn.max_pool(hidden,[1,2,2,1],[1,2,2,1],padding='VALID')\n",
    "    conv = tf.nn.conv2d(pooling, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    pooling = tf.nn.max_pool(hidden,[1,2,2,1],[1,2,2,1],padding='VALID')\n",
    "    shape = pooling.get_shape().as_list()\n",
    "    reshape = tf.reshape(pooling, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    if train:\n",
    "        reshape = tf.nn.dropout(reshape,0.5)\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden,0.5,seed=SEED)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    \n",
    "  \n",
    "  L2 = lamba*tf.nn.l2_loss(layer1_weights)+lamba*tf.nn.l2_loss(layer1_biases)+ lamba*tf.nn.l2_loss(layer2_weights)+lamba*tf.nn.l2_loss(layer2_biases)+ lamba*tf.nn.l2_loss(layer3_weights)+lamba*tf.nn.l2_loss(layer3_biases)+ lamba*tf.nn.l2_loss(layer4_weights)+lamba*tf.nn.l2_loss(layer4_biases)\n",
    "    \n",
    "  #### Rate decay\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.05, global_step,100000,0.95,staircase=True)\n",
    "    \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)+L2)\n",
    "  \n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 92.209244\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 50: 74.787781\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 66.4%\n",
      "Minibatch loss at step 100: 72.926582\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 150: 70.949699\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 200: 69.109177\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 250: 67.495178\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 300: 65.750160\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 350: 63.932228\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 400: 62.727989\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 450: 60.861019\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 500: 59.159462\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 550: 58.143524\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 600: 56.481926\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 650: 55.126587\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 700: 54.122002\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 750: 52.728424\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 800: 51.086121\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 850: 50.039833\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 900: 48.476471\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 950: 47.602394\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 1000: 46.159355\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1050: 45.157509\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1100: 43.979271\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1150: 42.938332\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1200: 42.145393\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1250: 40.836678\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 1300: 39.859173\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 1350: 38.965328\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 1400: 38.126316\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 1450: 37.093128\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1500: 36.495079\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 1550: 35.389572\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1600: 34.358345\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1650: 33.734001\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 1700: 32.683445\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 1750: 31.905735\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 1800: 31.280579\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 1850: 30.574005\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 1900: 29.755585\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 1950: 28.991798\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 2000: 28.446140\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 2050: 27.361059\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2100: 26.812494\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2150: 26.292564\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2200: 25.473856\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2250: 24.820955\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 2300: 24.513016\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 2350: 23.991329\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 2400: 23.367142\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2450: 22.623783\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2500: 22.223694\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2550: 21.474857\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2600: 20.938286\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2650: 20.624018\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 2700: 19.881687\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 2750: 19.470535\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 2800: 19.076180\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 2850: 18.652164\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2900: 18.129072\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 2950: 17.724997\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 3000: 17.446766\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "valid_error = []\n",
    "train_error = []\n",
    "with tf.Session(graph=graph,config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      train_accuracy = accuracy(predictions, batch_labels)\n",
    "      print('Minibatch accuracy: %.1f%%' % train_accuracy)\n",
    "      valid_accuracy =accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "      train_error.append(100-train_accuracy)\n",
    "      valid_error.append(100-valid_accuracy)\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12a234d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a1d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = len(valid_error)\n",
    "step = np.arange(size)\n",
    "plt.plot(step,train_error)\n",
    "plt.plot(step,valid_error)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
